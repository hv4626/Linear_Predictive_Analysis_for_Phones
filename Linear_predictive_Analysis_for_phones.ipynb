{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aACAcAw3iSz",
   "metadata": {
    "id": "0aACAcAw3iSz"
   },
   "source": [
    "#Linear Predictive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e1cc497-9fbf-43d9-ad7a-218dbf6b7da7",
   "metadata": {
    "id": "6e1cc497-9fbf-43d9-ad7a-218dbf6b7da7"
   },
   "outputs": [],
   "source": [
    "#Importing all the necessary libraries together throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a12fab2-0ed5-4019-a782-33b759ad86e9",
   "metadata": {
    "id": "7a12fab2-0ed5-4019-a782-33b759ad86e9"
   },
   "outputs": [],
   "source": [
    "import librosa #Import the librosa library, which is used for audio and music analysis.\n",
    "import librosa.display # Import the librosa.display submodule for displaying audio-related visualizations.\n",
    "import matplotlib.pyplot as plt # Import the matplotlib.pyplot module for creating plots and visualizations.\n",
    "%matplotlib inline\n",
    "import matplotlib.patches as patches\n",
    "import numpy as np # Import numpy as np, Numpy is used for numerical computations.\n",
    "import scipy as sp # Scipy is used for scientific and technical computing.\n",
    "from scipy import signal # Import the signal module from scipy for signal processing functions.\n",
    "import random #provides various random number generators.\n",
    "import scipy\n",
    "from scipy.signal import lfilter, freqz #Imports functions of linear filter and frequency Response of a filter.\n",
    "from scipy.fft import fft, ifft,fftfreq\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import spectrogram, hamming\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from IPython.display import display, Audio, HTML # Import the display, Audio, and HTML classes/functions from the IPython.display module.\n",
    "from control import TransferFunction\n",
    "from control import pzmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "895e6c12-017c-47ee-8951-736cea94702c",
   "metadata": {
    "id": "895e6c12-017c-47ee-8951-736cea94702c"
   },
   "outputs": [],
   "source": [
    "#defining necessary functions together to be used throughout the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vkrYT9ki3tD1",
   "metadata": {
    "id": "vkrYT9ki3tD1"
   },
   "source": [
    "#Pre-emphasis\n",
    "Pre-emphasis is a signal processing technique that enhances higher-frequency components in a signal to improve its quality for various applications. It is achieved by subtracting a fraction of the previous sample from the current one\n",
    "\n",
    "$y[n]=x[n]-k*x[n-1]$\n",
    "\n",
    "Where:\n",
    "\n",
    "$y[n]$ is the emphasized output signal.\n",
    "\n",
    "$x[n]$ is the original input signal.\n",
    "\n",
    "$k$ is a constant controlling the emphasis level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d6d7b9a-3b0e-4722-aa7e-9af0ee27d780",
   "metadata": {
    "id": "6d6d7b9a-3b0e-4722-aa7e-9af0ee27d780"
   },
   "outputs": [],
   "source": [
    "def pre_emphasis(input,k):\n",
    "  duration = len(input) # Calculate the duration (length) of the input signal\n",
    "  output = np.zeros_like(input) # Create an array to store the pre-emphasized signal, initialized with zeros\n",
    "  output[0] = input[0] # Create an array to store the pre-emphasized signal, initialized with zeros\n",
    "  for n in range(1,duration): # Loop through the input signal to perform pre-emphasi\n",
    "    output[n] = input[n] - k*input[n-1]  # Apply the pre-emphasis formula: y[n] = x[n] - k * x[n-1]\n",
    "  return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5BMwb1jY5BC7",
   "metadata": {
    "id": "5BMwb1jY5BC7"
   },
   "source": [
    "\"narrowband magnitude spectrum slice using a Hamming window\" is a method for isolating and analyzing a specific range of frequencies within a signal while minimizing distortion by applying a smoothing technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7ddb54f-aaa0-4840-8614-9f6c07ac464a",
   "metadata": {
    "id": "d7ddb54f-aaa0-4840-8614-9f6c07ac464a"
   },
   "outputs": [],
   "source": [
    "def narrowband_spectrum(input,duration,fs):\n",
    "    middle = int(len(input)//2) # Calculate the middle index of the input signal\n",
    "    window_length = int((duration/1000)*fs) # Calculate the middle index of the input signal\n",
    "    win_len_half = window_length//2 # Calculate the middle index of the input signal\n",
    "    windowed_input = input[middle-win_len_half:middle+win_len_half] # Extract a slice of the input signal centered around the middle point\n",
    "    output = np.hamming(window_length)*windowed_input # Extract a slice of the input signal centered around the middle point\n",
    "    #w,h = signal.freqz(output)\n",
    "    #frequency_reponse = (fs*w/(2*np.pi))/1000\n",
    "    #magnitude_dB = 20 * np.log10(h)\n",
    "    return output, middle, window_length\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-9XZsLkY59jO",
   "metadata": {
    "id": "-9XZsLkY59jO"
   },
   "source": [
    "Autocorrelation, denoted by $p_{k}$\n",
    " , is a statistical measure that assesses the correlation between data points in a time series at different time lags. It quantifies the degree to which a data point at time $t$ is related to a data point at time\n",
    "$t-k$, where $k$ is the time lag\n",
    "\n",
    "\n",
    "\\[\n",
    "\\rho_k = \\frac{\\sum_{t=k+1}^{N}(X_t - \\bar{X})(X_{t-k} - \\bar{X})}{\\sqrt{\\sum_{t=1}^{N}(X_t - \\bar{X})^2 \\sum_{t=k+1}^{N}(X_{t-k} - \\bar{X})^2}}\\]\n",
    "\n",
    "\n",
    "Where:\n",
    "- $rho_k$ is the autocorrelation at lag $k$.\n",
    "- $X_t$ represents the value of the time series at time $t$.\n",
    "- $\\barX$ is the mean (average) of the time series values.\n",
    "- $k$ is the time lag, indicating how many time periods back the correlation is being calculated.\n",
    "- $N$ is the total number of data points in the time series.\n",
    "\n",
    "In this formula, $rho_k$ varies between -1 (perfect negative correlation) and 1 (perfect positive correlation), with 0 signifying no correlation between the data points at the given time lag \\( k \\). Autocorrelation is a fundamental concept in time series analysis, offering insights into temporal dependencies and patterns within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d8ddbab-8b64-4735-8e38-51460fba60ce",
   "metadata": {
    "id": "8d8ddbab-8b64-4735-8e38-51460fba60ce"
   },
   "outputs": [],
   "source": [
    "def autocorrelation(input, p=None): # Calculate the autocorrelation of the 'input' signal using numpy's correlate function\n",
    "    R = np.correlate(input, input, mode='full')\n",
    "    # Since we're interested in the right half of the symmetric autocorrelation function,\n",
    "    # we slice 'R' to keep only that part.\n",
    "    R = R[-len(input):]\n",
    "    if p is None: # If 'p' is not specified, return the full autocorrelation function\n",
    "        return R  # Return full autocorrelation\n",
    "    else: # If 'p' is specified, return only the first 'p + 1' elements of the autocorrelation\n",
    "        return R[:p + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u1gxL0_v8H0r",
   "metadata": {
    "id": "u1gxL0_v8H0r"
   },
   "source": [
    "The Levinson-Durbin algorithm is a technique to efficiently estimate the coefficients of an autoregressive (AR) model. In a nutshell, it minimizes the prediction error step by step\n",
    "\n",
    "\\begin{align*}\n",
    "\\alpha_m &= \\frac{1}{E_m}\\left(E_m^+ - \\sum_{j=1}^{m-1}A_jX_{m-j}\\right)\\\\\n",
    "A_m &= -\\alpha_m\\\\\n",
    "X_m &= A_m - \\sum_{j=1}^{m-1}A_jX_{m-j}\n",
    "\\end{align*}\n",
    "\n",
    "$\\alpha_m$ is a reflection coefficient at each step. \\\\\n",
    "$A_m$ represents the AR model coefficients. \\\\\n",
    "$X_m$ is the prediction error. \\\\\n",
    "$E_m$ is the cumulative prediction error up to step $m$. \\\\\n",
    "$E_m^+$ is the prediction error after updating at step $m$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2307a46-4788-4f31-a929-b270ed1d057d",
   "metadata": {
    "id": "a2307a46-4788-4f31-a929-b270ed1d057d"
   },
   "outputs": [],
   "source": [
    "def levinson_algorithm(R, p):\n",
    "    # Initialize arrays for error, 'a' coefficients, gain, and 'k' coefficients\n",
    "    error = np.zeros(p + 1)\n",
    "    a = np.zeros((p + 1, p + 1))\n",
    "    gain = np.zeros(p + 1)\n",
    "    k = np.zeros(p + 1)\n",
    "    a[:, 0] = 1 # Initialize arrays for error, 'a' coefficients, gain, and 'k' coefficients\n",
    "    error[0] = R[0] # The initial error is set to the first element of R\n",
    "    k[1] = R[1] / error[0]  # Calculate the first reflection coefficient 'k'\n",
    "    a[1][1] = k[1] # Store the first 'k' coefficient in the 'a' matrix\n",
    "    error[1] = (1 - k[1] ** 2) * error[0] # Calculate the updated error and store it\n",
    "    gain[1] = np.sqrt(error[1]) # Calculate the gain factor for this step\n",
    "    for i in range(2, p + 1): # Loop for the remaining 'k' coefficients and 'a' coefficients\n",
    "        t = 0\n",
    "        for j in range(1, i):\n",
    "            t += a[i - 1][j] * R[i - j] # Compute a sum involving the previous 'a' coefficients and R values\n",
    "        k[i] = (R[i] - t) / error[i - 1] # Calculate the next reflection coefficient 'k'\n",
    "        a[i][i] = k[i] # Store this 'k' coefficient in the 'a' matrix\n",
    "        for j in range(1, i):\n",
    "            a[i][j] = a[i - 1][j] - k[i] * a[i - 1][i - j] # Compute the next row of 'a' coefficients\n",
    "        error[i] = (1 - k[i] ** 2) * error[i - 1]\n",
    "        gain[i] = np.sqrt(error[i]) # Calculate the gain factor for this step\n",
    "\n",
    "    return error, gain, a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "svNUGPyv856d",
   "metadata": {
    "id": "svNUGPyv856d"
   },
   "source": [
    "#linear_predictor Function\n",
    "\n",
    "\n",
    "a. Autocorrelation Calculation (r = autocorrelation(input))\n",
    "\n",
    "b. Levinson-Durbin Algorithm (error, gain, a = levinson_algorithm(r, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32e3a41b-a40f-4806-98a2-ff1df90cc6e6",
   "metadata": {
    "id": "32e3a41b-a40f-4806-98a2-ff1df90cc6e6"
   },
   "outputs": [],
   "source": [
    "def linear_predictor(input, p):\n",
    "    r = autocorrelation(input) # Calculate the autocorrelation of the input data.\n",
    "    error, gain, a = levinson_algorithm(r, p) # Use the Levinson-Durbin recursion algorithm to estimate the prediction error, prediction gain, and predictor coefficients.\n",
    "    return error, gain, a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qFKst1G3A3yU",
   "metadata": {
    "id": "qFKst1G3A3yU"
   },
   "source": [
    "#Pole Zero Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9b7b5e7-5625-442e-bdb0-d8212f07bd17",
   "metadata": {
    "id": "d9b7b5e7-5625-442e-bdb0-d8212f07bd17"
   },
   "outputs": [],
   "source": [
    "'''def plot_pole_zero(z, p):\n",
    "    # Create a figure/plot\n",
    "    fig, ax = plt.subplots()\n",
    "    # Create the unit circle\n",
    "    unit_circle = patches.Circle((0, 0), radius=1, fill=False, color='black', linestyle='dashed')\n",
    "    ax.add_patch(unit_circle)\n",
    "    # Add axes lines\n",
    "    plt.axvline(0, color='0.8')\n",
    "    plt.axhline(0, color='0.8')\n",
    "\n",
    "    # Plot the poles and zeros\n",
    "    plt.plot(p.real, p.imag, 'x', label='Poles')\n",
    "    plt.plot(z.real, z.imag, 'o', label='Zeros')\n",
    "\n",
    "    # Set the axis limits and ticks\n",
    "    axis_range = 1.5\n",
    "    plt.axis('scaled')\n",
    "    plt.axis([-axis_range, axis_range, -axis_range, axis_range])\n",
    "    ticks = [-1, -0.5, 0.5, 1]\n",
    "    plt.xticks(ticks)\n",
    "    plt.yticks(ticks)'''\n",
    "def plot_pole_zero(z, p):\n",
    "    plt.clf()  # Clear the previous plot\n",
    "    # Create a figure/plot\n",
    "    fig, ax = plt.subplots()\n",
    "    # Create the unit circle\n",
    "    unit_circle = patches.Circle((0, 0), radius=1, fill=False, color='black', ls='dashed')\n",
    "    ax.add_patch(unit_circle)\n",
    "    # Add axes lines\n",
    "    plt.axvline(0, color='0.8')\n",
    "    plt.axhline(0, color='0.8')\n",
    "    # Plot the poles and zeros\n",
    "    plt.plot(p.real, p.imag, 'x', label='Poles')\n",
    "    plt.plot(z.real, z.imag, 'o', label='Zeros')\n",
    "    # Set the axis limits and ticks\n",
    "    axis_range = 1.5\n",
    "    plt.axis('scaled')\n",
    "    plt.axis([-axis_range, axis_range, -axis_range, axis_range])\n",
    "    ticks = [-1, -0.5, 0.5, 1]\n",
    "    plt.xticks(ticks)\n",
    "    plt.yticks(ticks)\n",
    "    # Set labels and legend\n",
    "    plt.title(\"Pole-Zero Plot\")\n",
    "    plt.xlabel(\"Real\")\n",
    "    plt.ylabel(\"Imaginary\")\n",
    "\n",
    "def plot_pole_zero_for_p(narrowband_output, p): # Function to plot pole-zero diagram for a specific 'p' value.\n",
    "    error, gain, a = linear_predictor(narrowband_output, 10) # Perform linear prediction to get predictor coefficients.\n",
    "    coeff_den = [a[p][0], *(-a[p][1:p+1])] # Extract the denominator coefficients of the transfer function.\n",
    "    z, poles, k = signal.tf2zpk(gain[p], coeff_den) # Convert the coefficients to zeros, poles, and gain.\n",
    "    fig = plt.figure() # Create a new plot for the pole-zero diagram for 'p'\n",
    "    plt.title('Pole Zero plot for p=' + str(p))\n",
    "    plot_pole_zero(z, poles)\n",
    "    plt.grid(True, color='0.9')\n",
    "    print('Pole Zero plot for p=' + str(p))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5ad5d82-53b5-4626-b266-3ad1824e8fd9",
   "metadata": {
    "id": "b5ad5d82-53b5-4626-b266-3ad1824e8fd9"
   },
   "outputs": [],
   "source": [
    "def LPC_spectrum(a, G, fs, input, orders=[1, 2, 4, 6, 8, 10]):\n",
    "    num_orders = len(orders) # Calculate the number of orders to process\n",
    "    w_sig, h_sig = signal.freqz(input) # Calculate the frequency response of the original input signal\n",
    "    w_khz = (fs * w_sig / (2 * np.pi) / 1000)  # Convert the angular frequency to kilohertz\n",
    "    h_db = 20 * np.log10(abs(h_sig)) # Calculate the magnitude in decibels (dB) of the original signal\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    for idx, order in enumerate(orders, start=1):  # Loop through the specified LPC orders\n",
    "        poles = [a[order][0], *(-a[order][1:order + 1])]  # Extract the LPC poles from the 'a' coefficients\n",
    "        w, h = signal.freqz(G[order], poles) # Calculate the frequency response of the LPC filter with the specified order\n",
    "        plt.subplot(2, 3, idx)\n",
    "        plt.plot(w_khz, h_db, linestyle='dashed', label=\"Original Windowed\")\n",
    "        plt.plot((fs * w / (2 * np.pi) / 1000), 20 * np.log10(abs(h)), label=\"Estimated\") # Plot the original signal's frequency response as a dashed line # Plot the estimated LPC filter's frequency response\n",
    "        plt.title(f\"LPC spectrum for p = {order}\")\n",
    "        plt.xlabel(\"Frequency (KHz)\")\n",
    "        plt.ylabel(r\"Magnitude $|H(\\omega)|$ (dB)\")\n",
    "        plt.grid()\n",
    "        plt.xlim(xmin=0)\n",
    "        plt.legend()\n",
    "        plt.autoscale(enable=True, axis='x', tight=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q9ucE0ET-4cp",
   "metadata": {
    "id": "Q9ucE0ET-4cp"
   },
   "source": [
    "Given:\n",
    "\n",
    "gain is the prediction gain obtained from linear prediction.\n",
    "coeff is an array of prediction coefficients obtained from linear prediction.\n",
    "input is the input signal.\n",
    "Inverse Filtering (Inverse Filter):\n",
    "\n",
    "**1. Initialization:**\n",
    "   - Sampling rate: $F_s$\n",
    "   - Signal duration: $text{duration}$ (in seconds)\n",
    "   - Window duration in samples: $\\text{window_duration} = \\left(\\frac{\\text{duration}}{1000}\\right) \\cdot F_s $\n",
    "   - Length of input signal: ${length}$\n",
    "   - Create an initial inverse filter: \\( \\text{inverse_filter}$\n",
    "\n",
    "**2. Inverse Filtering:**\n",
    "   - For each sample \\( i \\) in the input signal:\n",
    "     - Initialize \\( \\text{inverse\\_filter}[i] \\) with the value of the input at that sample.\n",
    "     - For each prediction coefficient \\( j \\) in \\( \\text{coeff} \\):\n",
    "       - Update \\( \\text{inverse\\_filter}[i] \\) by subtracting the coefficient \\( \\text{coeff}[j] \\) times the input signal value at \\( i - j \\) samples.\n",
    "     - Normalize \\( \\text{inverse\\_filter}[i] \\) by dividing it by the prediction gain \\( \\text{gain} \\).\n",
    "\n",
    "**3. Autocorrelation:**\n",
    "   - Calculate the autocorrelation of the inverse filter:\n",
    "     \\[ \\text{r\\_inverse} = \\text{np.correlate}(\\text{inverse\\_filter}, \\text{inverse\\_filter}, \\text{mode}=\"same\") \\]\n",
    "   - Calculate the autocorrelation of the input signal:\n",
    "     \\[ \\text{r\\_signal} = \\text{np.correlate}(\\text{input}, \\text{input}, \\text{mode}=\"same\") \\]\n",
    "\n",
    "**4. Fundamental Frequency Estimation:**\n",
    "   - Find the indices of the first and second peaks in \\( \\text{r\\_inverse} \\):\n",
    "     \\[ \\text{first} = \\text{np.argmax}(\\text{r\\_inverse}) \\]\n",
    "     \\[ \\text{second} = \\text{np.argmax}(\\text{r\\_inverse}[\\text{r\\_inverse} < 0.8 \\cdot \\text{np.max}(\\text{r\\_inverse})]) \\]\n",
    "   - Calculate the fundamental frequency $F_0$ using the peak indices:\n",
    "     $ F_0 $= $\\frac{F_s}{\\text{first} - \\text{second}}$\n",
    "\n",
    "\n",
    "Where:\n",
    "Fs is the sampling rate of the signal.\n",
    "The algorithm essentially uses linear prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5038a072-0f93-4aa8-a955-70e872090517",
   "metadata": {
    "id": "5038a072-0f93-4aa8-a955-70e872090517"
   },
   "outputs": [],
   "source": [
    "def fundamental_frequency(gain, coeff, input):\n",
    "    Fs=44100 # Sampling rate\n",
    "    duration=30 # Sampling rate\n",
    "    window_duration = int((duration / 1000) * Fs) # Calculate the window duration in samples based on the signal duration\n",
    "    length = input.shape[0]\n",
    "    inverse_filter = np.copy(input) # Create a copy of the input signal for inverse filtering\n",
    "    for i in range(length): # Apply the inverse filter to estimate the fundamental frequency\n",
    "        for j in range(min(i + 1, len(coeff))):\n",
    "            inverse_filter[i] -= coeff[j] * input[i - j] # Update the inverse filter using the prediction coefficients\n",
    "        inverse_filter[i] /= gain  # Normalize the inverse filter by the prediction gain\n",
    "    r_inverse = np.correlate(inverse_filter, inverse_filter, mode=\"same\") # Compute the autocorrelation of the inverse filter and the input signal\n",
    "    r_signal = np.correlate(input, input, mode=\"same\")\n",
    "    first = np.argmax(r_inverse) # Find the first and second peaks in the autocorrelation of the inverse filter\n",
    "    second = np.argmax(r_inverse[r_inverse < 0.8 * np.max(r_inverse)])\n",
    "    F0 = Fs / (first - second) # Calculate the fundamental frequency (F0) using the peaks\n",
    "\n",
    "    return inverse_filter, F0, r_inverse, r_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "204f73fd-97b2-49b8-bf6e-74f2ebd12c7b",
   "metadata": {
    "id": "204f73fd-97b2-49b8-bf6e-74f2ebd12c7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def generate_triangular_excitation(pitch, duration, pulse_sample_width, sampling_frequency):\\n    samples_per_period = int(sampling_frequency / pitch)\\n    total_samples = int(sampling_frequency * duration)\\n    # Calculate the \"ON\" and \"OFF\" segments of the triangular pulse\\n    half_pulse_width = pulse_sample_width // 2\\n    on_segment = np.linspace(0, 1, half_pulse_width, endpoint=False)\\n    off_segment = np.linspace(1, 0, half_pulse_width)\\n    # Construct the full pulse\\n    pulse = np.concatenate((on_segment, off_segment))\\n    # Ensure the pulse length matches the desired width\\n    if len(pulse) > pulse_sample_width:\\n        pulse = pulse[:pulse_sample_width]\\n    elif len(pulse) < pulse_sample_width:\\n        pulse = np.pad(pulse, (0, pulse_sample_width - len(pulse)))\\n    # Initialize the source_excitation\\n    source_excitation = np.zeros(total_samples)\\n    # Replicate the pulse for the desired duration, taking care of boundaries\\n    for i in range(0, total_samples, samples_per_period):\\n        if i + len(pulse) <= total_samples:\\n            source_excitation[i:i + len(pulse)] = pulse\\n        else:\\n            source_excitation[i:] = pulse[:total_samples - i]\\n\\n    time_values = np.linspace(0, duration, total_samples)\\n\\n    return source_excitation, time_values\\n    '"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_triangular_excitation(pitch, duration, pulse_sample_width, sampling_frequency):\n",
    "    samples_per_period = int(sampling_frequency / pitch)\n",
    "    total_samples = int(sampling_frequency * duration)\n",
    "    # Calculate the \"ON\" and \"OFF\" segments of the triangular pulse\n",
    "    half_pulse_width = pulse_sample_width // 2\n",
    "    on_segment = np.linspace(0, 1, half_pulse_width, endpoint=False)\n",
    "    off_segment = np.linspace(1, 0, half_pulse_width)\n",
    "    # Construct the full pulse\n",
    "    pulse = np.concatenate((on_segment, off_segment))\n",
    "    # Ensure the pulse length matches the desired width\n",
    "    if len(pulse) > pulse_sample_width:\n",
    "        pulse = pulse[:pulse_sample_width]\n",
    "    elif len(pulse) < pulse_sample_width:\n",
    "        pulse = np.pad(pulse, (0, pulse_sample_width - len(pulse)))\n",
    "    # Initialize the source_excitation\n",
    "    source_excitation = np.zeros(total_samples)\n",
    "    # Replicate the pulse for the desired duration, taking care of boundaries\n",
    "    for i in range(0, total_samples, samples_per_period):\n",
    "        if i + len(pulse) <= total_samples:\n",
    "            source_excitation[i:i + len(pulse)] = pulse\n",
    "        else:\n",
    "            source_excitation[i:] = pulse[:total_samples - i]\n",
    "\n",
    "    time_values = np.linspace(0, duration, total_samples)\n",
    "\n",
    "    return source_excitation, time_values\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
